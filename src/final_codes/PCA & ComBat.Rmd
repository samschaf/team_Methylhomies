---
output: 
  html_document: 
    keep_md: yes
---
Hannon et al. (2017) 450K Data Principal Component Analysis
========================================================
## Original author: Sumaiya Islam
## Updated by: Samantha Schaffner
## Date updated: March 13, 2017
  
### Script contents:
  - detection and correction for technical batch variation using PCA and ComBat, respectively, of post-mortem human brain samples analyzed by Illumina HM450K platform from Jonathan Mill's research group (PMC4844197). 
   
### A. Set up working directory & packages

R version 3.2.3 (2015-12-10)

We will initially set our working directory and load our libraries.

```{r,include=FALSE}
library(reshape)
library(ggplot2)
library(RColorBrewer)
library(grid)
library(gridExtra)
library(sva)
library(rama)
library(methylumi)
library(gplots)
library(marray)
library(lumi)
library(lattice)
library("RColorBrewer")
library(knitr)
library(xtable)
library(wateRmelon)
library(limma)
library(RPMM)
library(dplyr)
```

## Heat scree plot Function
```{r}
### Function of association meta variable with PC (ANOVA)
heat_scree_plot<-function(Loadings, Importance, Num, Order){
  adjust<-1-Importance[1]
  pca_adjusted<-Importance[2:length(Importance)]/adjust
  pca_df<-data.frame(adjusted_variance=pca_adjusted, PC=seq(1:length(pca_adjusted)))
  
  scree<-ggplot(pca_df[which(pca_df$PC<Num),],aes(PC,adjusted_variance))+geom_bar(stat = "identity",color="black",fill="grey")+theme_bw()+
        theme(axis.text = element_text(size =12),
              axis.title = element_text(size =15),
              plot.margin=unit(c(1,1.5,0.2,2.25),"cm"))+ylab("Variance")+
    scale_x_continuous(breaks = seq(1,Num,1))
  
  #### Heat
  ## correlate meta with PCS
  ## Run anova of each PC on each meta data variable

  aov_PC_meta<-lapply(1:ncol(meta_categorical), function(covar) sapply(1:ncol(Loadings), function(PC) summary(aov(Loadings[,PC]~meta_categorical[,covar]))[[1]]$"Pr(>F)"[1]))
  cor_PC_meta<-lapply(1:ncol(meta_continuous), function(covar) sapply(1:ncol(Loadings), function(PC) (cor.test(Loadings[,PC],as.numeric(meta_continuous[,covar]),alternative = "two.sided", method="spearman", na.action=na.omit, exact=FALSE)$p.value)))
  names(aov_PC_meta)<-colnames(meta_categorical)
  names(cor_PC_meta)<-colnames(meta_continuous)
  aov_PC_meta<-do.call(rbind, aov_PC_meta)
  cor_PC_meta<-do.call(rbind, cor_PC_meta)
 aov_PC_meta<-rbind(aov_PC_meta, cor_PC_meta)
  aov_PC_meta<-as.data.frame(aov_PC_meta)
  #adjust
  aov_PC_meta_adjust<-aov_PC_meta[,2:ncol(aov_PC_meta)]
  
    
  #reshape
  avo<-aov_PC_meta_adjust[,1:(Num-1)]
  avo_heat_num<-apply(avo,2, as.numeric)
  avo_heat<-as.data.frame(avo_heat_num)
  colnames(avo_heat)<-sapply(1:(Num-1), function(x) paste("PC",x, sep=""))
  avo_heat$meta<-rownames(avo)
  avo_heat_melt<-melt(avo_heat, id=c("meta"))
  
  # cluster meta data
  ord <- Order
  meta_var_order<-unique(avo_heat_melt$meta)[rev(ord)]
  avo_heat_melt$meta <- factor(avo_heat_melt$meta, levels = meta_var_order)
  
  # color if sig
   avo_heat_melt$Pvalue<-sapply(1:nrow(avo_heat_melt), function(x) if(avo_heat_melt$value[x]>=0.9){">=0.9"}else{
    if(avo_heat_melt$value[x]>=0.5){">=0.5"}else{
      if(avo_heat_melt$value[x]>=0.1){">=0.1"}else{"<0.1"}}})
  avo_heat_melt$Pvalue<-sapply(1:nrow(avo_heat_melt), function(x) if(avo_heat_melt$value[x]<=0.001){"<=0.001"}else{
     if(avo_heat_melt$value[x]<=0.01){"<=0.01"}else{
       if(avo_heat_melt$value[x]<=0.05){"<=0.05"}else{">0.05"}}})
  
  heat<-ggplot(avo_heat_melt, aes(variable,meta, fill = Pvalue)) +
  geom_tile(color = "black",size=0.5) +
  theme_gray(8)+scale_fill_manual(values=c("#084594","#4292c6","#9ecae1","#deebf7"))+
      theme(axis.text = element_text(size =10, color="black"),
            axis.text.x = element_text(),
          axis.title = element_text(size =15),
          legend.text = element_text(size =14),
          legend.title = element_text(size =12),
          legend.position = c(1, 0), legend.justification = c(1,0),
          plot.margin=unit(c(0,2.25,1,1),"cm"))+
    xlab("Principal Component")+ylab(NULL)
  
  grid.arrange(scree, heat, ncol=1)
}
```


### B. Load files

#### We will be analyzing the normalized and filtered Hannon et al. dataset

```{r}

load("GSE59685_filtered_brain.RData") # normalized beta values
GSE59685_filtered_brain[] <- lapply(GSE59685_filtered_brain, as.character)
GSE59685_filtered_brain[] <- lapply(GSE59685_filtered_brain, as.numeric)
load("Meta_matched_brain.RData") # associated meta data
cell.proportions<-read.csv("Hannon_Neuronal_Glia_Proportions.csv", header=TRUE, row.names=1) # predicted neuron and glial cell proportions based on CETS
head(cell.proportions)

# check for NAs in data
GSE59685_filtered_brain <- as.matrix(GSE59685_filtered_brain)
ind<-is.row.na(GSE59685_filtered_brain) # The function returns a vector of logical variables, one for each row of the matrix. The variable is TRUE if the row does not contain any missing values and FAlSE otherwise.
length(na.count<-which(ind=="FALSE")) # 0 (there are no rows that contain a NA in the raw data)


uncor.dat<-GSE59685_filtered_brain
meta<-Meta_matched_brain

#Restructure meta data and cell proportion data so sample order matches
meta<- meta %>% arrange(gsm)
cell.proportions$gsm <- rownames(cell.proportions)
cell.proportions<- cell.proportions %>% arrange(gsm)

#Add cell proportion information to meta data
identical(cell.proportions$gsm, meta$gsm) # TRUE
meta$Neuron<-as.numeric(cell.proportions$neuron)
meta$Glia<-as.numeric(cell.proportions$glia)
```


## PCA Scree Heatmap for uncorrected data

```{r warning=FALSE, fig.height=9, fig.width=11}
## PCA
PCA_full<-princomp(uncor.dat[complete.cases(uncor.dat),]) # scaling is not necessary for normalized dataset
Loadings<-as.data.frame(unclass(PCA_full$loadings))
vars <- PCA_full$sdev^2
Importance<-vars/sum(vars)
adjust<-1-Importance[1]
pca_adjusted<-Importance[2:length(Importance)]/adjust
pca_df<-data.frame(adjusted_variance=pca_adjusted, PC=seq(1:length(pca_adjusted)))

#Specify which covariates are categorical and/or categorical
colnames(meta)
meta_categorical<-meta[,c("ad.disease.status", "braak.stage", "Sex", "Tissue", "chip", "row")]  # input column numbers in meta that contain categorical variables
meta_continuous<-meta[,c("age.brain", "Neuron")] # input column numbers in meta that contain continuous variables
#meta_continuous<-data.frame(meta_continuous)

# Specify the number of PCs you want shown (usually # of samples in the dataset)
Num<-20

# Designate what order you want the variables to appear (continuous variables rbinded to categorical variables in function)
Order<-c(4,8,7,3,1,2,5,6)

#Apply function on PCA results, pulls in the meta data and beta values from above
heat_scree_plot(Loadings, Importance, Num, Order)
```

The main contributors to variance in this data are age, Alzheimer's disease status, Braak Stage, and chip, with some row effects showing up in PC's 8-12. Sex has a minor effect in PC 17. AD status, Braak Stage, age, and sex will be used as covariates in a linear regression model, while the chip and row effects will be batch-corrected using ComBat.

## Batch correction using ComBat

ComBat is a function included in the SVA (surrogate variable analysis) package ((Johnson et al., 2007))[https://academic.oup.com/biostatistics/article-lookup/doi/10.1093/biostatistics/kxj037]. It uses empirical Bayesian adjustment to correct for known sources of batch variation. Correction is usually performed first on either the variable which contributes more to overall variance or the variable with fewer batches -- row satisfies both of these requirements, so we will correct for row, followed by chip.

```{r}
#Add row and chip information to metadata; this can be found in the sample barcodes
barcodes <- read.csv("GSE59685_SampleBarcode_Re-analyzedGSMs_NewGSMs.txt.gz", sep="\t")
barcodes <- barcodes %>% arrange(NEW_GSMs)
for (i in 1:nrow(meta)){
  for (j in 1:nrow(barcodes)){
    if (meta$gsm[i]==barcodes$NEW_GSMs[j]){
  meta$chip[i]<-paste(substr(barcodes[j,"Sample_Barcode"], start=1, stop=10))
  meta$row[i]<-paste(substr(barcodes[j,"Sample_Barcode"], start=13, stop=14))
}}}
meta$age.brain <- as.numeric(meta$age.brain)
str(meta)
save(meta, file="Meta_brain_batch.RData")

#Correction for row
row <- meta$row
modcombat <- model.matrix(~1,data=meta)
combat_edata <- ComBat(dat=GSE59685_filtered_brain, batch=row, mod=modcombat, par.prior=TRUE, prior.plots=FALSE)

#Correction for chip
chip <- meta$chip
GSE59685_batch_cor <- ComBat(dat=combat_edata, batch=chip, mod=modcombat, par.prior=TRUE, prior.plots=FALSE)
save(GSE59685_batch_cor, file="GSE59685_batch_cor.RData")
```

## Predict cell proportions for batch-corrected data

```{r}
library(cets)
# load "brain dataset" from data file in cetsBrain
load("~/team_Methylhomies/cetsBrain.rda") # click on cetsBrain.rda file to place in workspace
dim(brain)
brain[1:3, 1:4]
head(pdBrain)
```

Create the neuron and glia reference profiles:

```{r}
modelIdx <- list(neuron = pdBrain$celltype == "N", glia = pdBrain$celltype ==  "G")
 # getReference returns a 2-column matrix, representing reference profiles for the two cell types.
refProfile <- getReference(brain, modelIdx)
head(refProfile)
```

#### For the brain datasets

Estimate the neuronal proportion:

The estProportion function returns an estimate of the percentage of cell type in the first column of its profile argument (neurons in this case). 
```{r}
prop <- estProportion(GSE59685_batch_cor, profile = refProfile)
prop<-as.data.frame(prop)
prop$glia<-apply(prop,1,function(x) 1-x)
colnames(prop)<- c("neuron", "glia")
head(prop)
write.csv(prop, file = "cellprop_batch_cor.csv", row.names=T)
summary(prop)
plot(density(prop$neuron), main="Neuronal Proportion Density") 
```

```{r}
#Restructure meta data and cell proportion data so sample order matches
cell.proportions <- prop
cell.proportions$gsm <- rownames(cell.proportions)
cell.proportions<- cell.proportions %>% arrange(gsm)

#Add cell proportion information to meta data
identical(cell.proportions$gsm, meta$gsm) # TRUE
meta$Neuron<-as.numeric(cell.proportions$neuron)
meta$Glia<-as.numeric(cell.proportions$glia)
```

## PCA Scree Heatmap for batch-corrected data

```{r warning=FALSE, fig.height=9, fig.width=11}
## PCA
PCA_full<-princomp(GSE59685_batch_cor[complete.cases(GSE59685_batch_cor),]) # scaling is not necessary for normalized dataset
Loadings<-as.data.frame(unclass(PCA_full$loadings))
vars <- PCA_full$sdev^2
Importance<-vars/sum(vars)
adjust<-1-Importance[1]
pca_adjusted<-Importance[2:length(Importance)]/adjust
pca_df<-data.frame(adjusted_variance=pca_adjusted, PC=seq(1:length(pca_adjusted)))

#Apply function on PCA results, pulls in the meta data and beta values from above
heat_scree_plot(Loadings, Importance, Num, Order)
```

We will now perform cell-type correction based on the neuronal/glial proportions

```{r}
all(rownames(prop)%in%colnames(GSE59685_batch_cor))
brain.cor.dat<- as.data.frame(GSE59685_batch_cor)

# fit methylation data for each probe in the dataset by the neuronal proportion
avebeta.lm<-apply(brain.cor.dat, 1, function(x){
  brain.sub<-prop[colnames(brain.cor.dat),]
  lm(x~neuron,data=brain.sub)
})

# obtain residuals for each probe across all samples (as a matrix)
residuals<-t(sapply(avebeta.lm, function(x)residuals(summary(x))))
head(residuals)
colnames(residuals)<-colnames(brain.cor.dat)

# generate adjusted residuals by adding the mean beta of each probe to the residuals
adj.residuals<-residuals+matrix(apply(brain.cor.dat, 1, mean), nrow=nrow(residuals), ncol=ncol(residuals))

r1<-as.data.frame(adj.residuals)
head(brain.cor.dat)
# check difference between corrected and uncorrected methylation data
all.equal(r1,brain.cor.dat)
```


To make sure we do not induce any NAs into the dataset when we convert the beta values back M-values (by log2 transformation), we need to ensure we do not have any corrected beta values that are greater or equal to zero or any beta values that are greater than 1.

```{r}
adj.residuals[adj.residuals<=0]<-0.001 # convert any values that are less than or equal to zero to 0.001
adj.residuals[adj.residuals>1]<-0.999 # convert any values that are greater than 1 to 0.999
adj.M.values<-beta2m(adj.residuals)
any(is.na(adj.M.values)) # should be FALSE indicating there are no NAs
```

Save corrected dataset:
```{r}
GSE59685_cell_cor<-adj.residuals
save(GSE59685_cell_cor, file="GSE59685_cell_cor.RData")
```

## PCA Scree Heatmap for cell-corrected data

```{r warning=FALSE, fig.height=9, fig.width=11}
## PCA
cor.dat <- GSE59685_cell_cor
PCA_full<-princomp(cor.dat[complete.cases(cor.dat),]) # scaling is not necessary for normalized dataset
Loadings<-as.data.frame(unclass(PCA_full$loadings))
vars <- PCA_full$sdev^2
Importance<-vars/sum(vars)
adjust<-1-Importance[1]
pca_adjusted<-Importance[2:length(Importance)]/adjust
pca_df<-data.frame(adjusted_variance=pca_adjusted, PC=seq(1:length(pca_adjusted)))

#Apply function on PCA results, pulls in the meta data and beta values from above
heat_scree_plot(Loadings, Importance, Num, Order)
```

